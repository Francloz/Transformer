# Transformer

In this repository you can find:
  1. a replication of the model from the paper Attention is all you need using the torchtext utils from PyTorch,
  2. utils from https://github.com/jadore801120/attention-is-all-you-need-pytorch to preprocess the data and for future comparisons,
  3. TODO: accelerated Transformer model.
